---
title: "Multimodal PTSD Detection System"
excerpt: "A research-oriented multimodal AI system integrating text, audio, and video signals for PTSD detection in telehealth and clinical decision-support settings."
collection: portfolio
---

## Overview

This project presents the design and implementation of a **multimodal machine learning system** for the detection of **Post-Traumatic Stress Disorder (PTSD)** using **text, audio, and video modalities**. The system was developed with a strong focus on **real-world telehealth deployment**, emphasizing scalability, low-latency inference, and clinical usability.

The work explores how heterogeneous data sources can be effectively integrated to support reliable and robust prediction in sensitive healthcare contexts.

---

## Methodology

- Multimodal data preprocessing and feature extraction across **natural language, audio signals, and video frames**
- Deep learning–based modeling implemented in **PyTorch**
- Integration of modality-specific pipelines into a **unified inference architecture**
- Deployment-oriented backend exposed via **FastAPI**
- Modular, reproducible, and extensible system design

---

## Technologies

- **Programming & Frameworks:** Python, PyTorch
- **NLP & Multimodal Models:** Hugging Face Transformers
- **Backend & Deployment:** FastAPI
- **Data Management:** SQL, SQLite

---

## Results & Impact

- Achieved **near real-time inference performance**, suitable for telehealth applications
- Successfully unified **NLP and computer vision pipelines** within a single scalable backend
- Demonstrated the practical feasibility of **multimodal AI systems** for clinical decision-support workflows
- Delivered a complete, deployable prototype aligned with healthcare AI requirements

---

## Status

**Completed research project (2024–2025)**
